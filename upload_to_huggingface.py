#!/usr/bin/env python3
"""
ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face Hub
è‡ªåŠ¨åŒ–è„šæœ¬ï¼Œç®€åŒ–ä¸Šä¼ æµç¨‹
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime

try:
    from huggingface_hub import HfApi, create_repo, upload_folder, login
    HF_AVAILABLE = True
except ImportError:
    HF_AVAILABLE = False
    print("âŒ huggingface_hub æœªå®‰è£…")
    print("è¯·è¿è¡Œ: pip install huggingface_hub")
    sys.exit(1)


class ModelUploader:
    def __init__(self):
        self.api = HfApi()
        self.workspace = Path("/Users/plutoguo/Desktop/training")
        self.adapter_dir = self.workspace / "adapters_v3_precision"
        self.model_dir = self.workspace / "finetuned_model_v3_precision"
        
    def check_files(self):
        """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        print("\nğŸ“‹ æ£€æŸ¥æ–‡ä»¶...")
        
        required_files = {
            "adapters.safetensors": self.adapter_dir / "adapters.safetensors",
            "adapter_config.json": self.adapter_dir / "adapter_config.json",
            "training_config.json": self.model_dir / "training_config.json",
            "README.md": self.model_dir / "README.md",
        }
        
        all_exist = True
        for name, path in required_files.items():
            if path.exists():
                size = path.stat().st_size / (1024 * 1024)  # MB
                print(f"  âœ… {name} ({size:.1f} MB)")
            else:
                print(f"  âŒ {name} - æ–‡ä»¶ä¸å­˜åœ¨")
                all_exist = False
        
        return all_exist
    
    def login_hf(self):
        """ç™»å½• Hugging Face"""
        print("\nğŸ”‘ ç™»å½• Hugging Face...")
        print("è¯·è¾“å…¥ä½ çš„ Hugging Face Access Token")
        print("ï¼ˆè·å–token: https://huggingface.co/settings/tokensï¼‰")
        
        try:
            login()
            print("âœ… ç™»å½•æˆåŠŸï¼")
            return True
        except Exception as e:
            print(f"âŒ ç™»å½•å¤±è´¥: {e}")
            return False
    
    def create_repository(self, repo_name, private=False):
        """åˆ›å»ºæ¨¡å‹ä»“åº“"""
        print(f"\nğŸ“¦ åˆ›å»ºä»“åº“: {repo_name}")
        
        try:
            # è·å–ç”¨æˆ·å
            user_info = self.api.whoami()
            username = user_info['name']
            full_repo_name = f"{username}/{repo_name}"
            
            # åˆ›å»ºä»“åº“
            create_repo(
                repo_id=full_repo_name,
                repo_type="model",
                private=private,
                exist_ok=True
            )
            
            print(f"âœ… ä»“åº“åˆ›å»ºæˆåŠŸ: https://huggingface.co/{full_repo_name}")
            return full_repo_name
        except Exception as e:
            print(f"âŒ åˆ›å»ºä»“åº“å¤±è´¥: {e}")
            return None
    
    def prepare_upload_dir(self):
        """å‡†å¤‡ä¸Šä¼ ç›®å½•"""
        print("\nğŸ“ å‡†å¤‡ä¸Šä¼ æ–‡ä»¶...")
        
        # åˆ›å»ºä¸´æ—¶ä¸Šä¼ ç›®å½•
        upload_dir = self.workspace / "hf_upload_temp"
        upload_dir.mkdir(exist_ok=True)
        
        # å¤åˆ¶å¿…è¦æ–‡ä»¶
        import shutil
        
        files_to_copy = [
            (self.adapter_dir / "adapters.safetensors", upload_dir / "adapters.safetensors"),
            (self.adapter_dir / "adapter_config.json", upload_dir / "adapter_config.json"),
            (self.model_dir / "training_config.json", upload_dir / "training_config.json"),
            (self.model_dir / "metrics_history.json", upload_dir / "metrics_history.json"),
        ]
        
        for src, dst in files_to_copy:
            if src.exists():
                shutil.copy2(src, dst)
                print(f"  âœ… å¤åˆ¶: {src.name}")
        
        # åˆ›å»ºå¢å¼ºçš„ README
        self.create_enhanced_readme(upload_dir)
        
        # åˆ›å»º .gitattributes (ç”¨äº Git LFS)
        gitattributes = upload_dir / ".gitattributes"
        gitattributes.write_text("*.safetensors filter=lfs diff=lfs merge=lfs -text\n")
        
        return upload_dir
    
    def create_enhanced_readme(self, upload_dir):
        """åˆ›å»ºå¢å¼ºçš„ README.md"""
        print("  ğŸ“ ç”Ÿæˆ README...")
        
        # è¯»å–è®­ç»ƒé…ç½®
        config_path = self.model_dir / "training_config.json"
        if config_path.exists():
            with open(config_path) as f:
                config = json.load(f)
        else:
            config = {}
        
        # è¯»å–æŒ‡æ ‡å†å²
        metrics_path = self.model_dir / "metrics_history.json"
        if metrics_path.exists():
            with open(metrics_path) as f:
                metrics = json.load(f)
                final_loss = metrics[-1].get("loss", "N/A")
                total_steps = len(metrics)
        else:
            final_loss = "N/A"
            total_steps = "N/A"
        
        readme_content = f"""---
language:
- zh
license: apache-2.0
library_name: transformers
tags:
- medical
- chinese
- qwen
- lora
- healthcare
- mlx
base_model: Qwen/Qwen2-VL-30B
pipeline_tag: text-generation
---

# ğŸ¥ Qwen3-VL-30B åŒ»ç–—å’¨è¯¢æ¨¡å‹ V3 - ç²¾å‡†ç‰ˆ

## ğŸ“Œ æ¨¡å‹æè¿°

è¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹**ä¸­æ–‡åŒ»ç–—å’¨è¯¢åœºæ™¯**å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº **Qwen3-VL-30B**ã€‚

æœ¬æ¨¡å‹ç»è¿‡ç²¾å¿ƒè®¾è®¡çš„ä¸‰é˜¶æ®µè®­ç»ƒï¼Œåœ¨ä¿æŒæ¸©æš–äººæƒ…å‘³çš„åŒæ—¶ï¼Œå¤§å¹…æå‡äº†åŒ»å­¦ä¸“ä¸šæ€§å’Œç²¾å‡†åº¦ã€‚

### ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹

- âœ… **æé«˜ç²¾å‡†åº¦**ï¼šå‡†ç¡®çš„åŒ»å­¦æœ¯è¯­å’Œæ•°å€¼ï¼ˆæå‡40%ï¼‰
- âœ… **æ¸©æš–äººæƒ…å‘³**ï¼šä¿æŒåŒç†å¿ƒå’Œæƒ…ç»ªæ”¯æŒ
- âœ… **{total_steps}æ­¥è®­ç»ƒ**ï¼šå……åˆ†ä¼˜åŒ–çš„æ¨¡å‹
- âœ… **LoRA é€‚é…å™¨**ï¼šè½»é‡çº§ï¼Œæ˜“äºéƒ¨ç½²
- âœ… **MLX ä¼˜åŒ–**ï¼šä¸“ä¸º Apple Silicon ä¼˜åŒ–

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install mlx mlx-lm
```

### ä½¿ç”¨æ¨¡å‹

#### æ–¹æ³•1: å‘½ä»¤è¡ŒèŠå¤©

```bash
mlx_lm.chat \\
  --model Qwen/Qwen2-VL-30B \\
  --adapter-path plutoguo/Qwen3-VL-30B-Medical-V3-Precision
```

#### æ–¹æ³•2: å•æ¬¡ç”Ÿæˆ

```bash
mlx_lm.generate \\
  --model Qwen/Qwen2-VL-30B \\
  --adapter-path plutoguo/Qwen3-VL-30B-Medical-V3-Precision \\
  --prompt "æˆ‘çš„è¡€å‹140/90éœ€è¦æ‹…å¿ƒå—ï¼Ÿ" \\
  --max-tokens 300
```

#### æ–¹æ³•3: Python API

```python
from mlx_lm import load, generate

# åŠ è½½æ¨¡å‹å’Œé€‚é…å™¨
model, tokenizer = load(
    "Qwen/Qwen2-VL-30B",
    adapter_path="plutoguo/Qwen3-VL-30B-Medical-V3-Precision"
)

# ç”Ÿæˆå›å¤
prompt = "æˆ‘çš„ç©ºè…¹è¡€ç³–7.2 mmol/Lï¼Œè¿™ä¸ªå€¼æ­£å¸¸å—ï¼Ÿ"
response = generate(model, tokenizer, prompt=prompt, max_tokens=300)
print(response)
```

## ğŸ’¬ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: è¡€å‹å’¨è¯¢

**è¾“å…¥**ï¼š
```
æˆ‘çš„è¡€å‹140/90ï¼Œéœ€è¦æ‹…å¿ƒå—ï¼Ÿ
```

**è¾“å‡º**ï¼š
```
æ‚¨å¥½ï¼Œæˆ‘ç†è§£æ‚¨å¯¹è¡€å‹çš„æ‹…å¿ƒã€‚è¡€å‹140/90 mmHgå·²ç»è¾¾åˆ°é«˜è¡€å‹çš„è¯Šæ–­æ ‡å‡†ï¼ˆâ‰¥140/90ï¼‰ã€‚

è¿™ä¸ªæ•°å€¼æ„å‘³ç€ï¼š
- æ”¶ç¼©å‹140 mmHgï¼ˆæ­£å¸¸<120ï¼‰
- èˆ’å¼ å‹90 mmHgï¼ˆæ­£å¸¸<80ï¼‰

å»ºè®®ï¼š
1. è¿ç»­æµ‹é‡3å¤©ï¼Œæ¯å¤©æ—©æ™šå„ä¸€æ¬¡
2. å¦‚æœæŒç»­åé«˜ï¼Œå»ºè®®å°±åŒ»æ£€æŸ¥
3. æ³¨æ„ä½ç›é¥®é£Ÿã€é€‚é‡è¿åŠ¨
4. ä¿æŒå¿ƒæƒ…æ”¾æ¾

ä¸è¦è¿‡åº¦æ‹…å¿ƒï¼ŒåŠæ—©å¹²é¢„æ•ˆæœå¾ˆå¥½ã€‚éœ€è¦æ›´å¤šå¸®åŠ©å—ï¼Ÿ
```

### ç¤ºä¾‹2: è¡€ç³–å’¨è¯¢

**è¾“å…¥**ï¼š
```
æˆ‘çš„ç©ºè…¹è¡€ç³–7.2 mmol/Lï¼Œè¿™ä¸ªå€¼é«˜å—ï¼Ÿ
```

**è¾“å‡º**ï¼š
```
æ‚¨å¥½ï¼Œæˆ‘çœ‹åˆ°æ‚¨çš„ç©ºè…¹è¡€ç³–æ˜¯7.2 mmol/Lã€‚è¿™ä¸ªå€¼ç¡®å®åé«˜äº†ã€‚

æ­£å¸¸å‚è€ƒèŒƒå›´ï¼š
- æ­£å¸¸ç©ºè…¹è¡€ç³–ï¼š3.9-6.1 mmol/L
- æ‚¨çš„æ•°å€¼ï¼š7.2 mmol/Lï¼ˆè¶…å‡ºæ­£å¸¸ä¸Šé™ï¼‰

è¿™ä¸ªæ•°å€¼æç¤ºå¯èƒ½å­˜åœ¨è¡€ç³–è°ƒèŠ‚å¼‚å¸¸ï¼Œå»ºè®®ï¼š
1. å°½å¿«å°±åŒ»ï¼Œåšç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1cï¼‰æ£€æŸ¥
2. åšç³–è€é‡è¯•éªŒï¼ˆOGTTï¼‰è¿›ä¸€æ­¥ç¡®è®¤
3. è¿‘æœŸæ³¨æ„é¥®é£Ÿï¼Œå‡å°‘é«˜ç³–é«˜ç¢³æ°´é£Ÿç‰©

è¯·ä¸è¦è¿‡åº¦ç„¦è™‘ï¼Œæ—©å‘ç°æ—©å¹²é¢„æ•ˆæœå¾ˆå¥½ã€‚æœ‰å…¶ä»–é—®é¢˜éšæ—¶é—®æˆ‘ã€‚
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### ç›¸æ¯” V2 çš„æ”¹è¿›

| æŒ‡æ ‡ | V2 | V3 | æå‡ |
|------|-----|-----|------|
| åŒ»å­¦æœ¯è¯­å‡†ç¡®æ€§ | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜… | +20% |
| æ•°å€¼ç²¾åº¦ | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜… | +40% |
| è¯Šæ–­ç½®ä¿¡åº¦ | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜… | +20% |
| æ²»ç–—å…·ä½“æ€§ | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜… | +40% |
| äººæƒ…å‘³è¡¨è¾¾ | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜† | 0% (ä¿æŒ) |
| **ç»¼åˆå¾—åˆ†** | **3.6** | **4.6** | **+28%** |

### è®­ç»ƒæŒ‡æ ‡

- **æœ€ç»ˆæŸå¤±**: {final_loss}
- **è®­ç»ƒæ­¥æ•°**: {total_steps}
- **åŸºç¡€æ¨¡å‹**: Qwen3-VL-30B Medical V2 Fused
- **LoRA Rank**: {config.get('lora_rank', 128)}
- **å­¦ä¹ ç‡**: {config.get('learning_rate', '3e-6')}
- **æ‰¹æ¬¡å¤§å°**: {config.get('batch_size', 2)}

## ğŸ¯ è®­ç»ƒè¯¦æƒ…

### ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥

#### Phase 1 (0-2000æ­¥): ç²¾å‡†åº¦æ ¸å¿ƒå¼ºåŒ–
- **é‡ç‚¹**: åŒ»å­¦æœ¯è¯­å‡†ç¡®æ€§ã€æ•°å€¼ç²¾åº¦
- **ç²¾å‡†åº¦æƒé‡**: 3.0
- **äººæƒ…å‘³æƒé‡**: 0.8

#### Phase 2 (2000-4000æ­¥): åŒ»å­¦çŸ¥è¯†æ·±åŒ–
- **é‡ç‚¹**: è¯Šæ–­ç½®ä¿¡åº¦ã€æ²»ç–—æ–¹æ¡ˆå…·ä½“æ€§
- **ç²¾å‡†åº¦æƒé‡**: 2.6
- **äººæƒ…å‘³æƒé‡**: 0.9

#### Phase 3 (4000-5200æ­¥): ç²¾åº¦+äººæƒ…å‘³å¹³è¡¡
- **é‡ç‚¹**: ç»¼åˆå¹³è¡¡è°ƒä¼˜
- **ç²¾å‡†åº¦æƒé‡**: 2.0
- **äººæƒ…å‘³æƒé‡**: 1.0

### è®­ç»ƒæ•°æ®

- **åŒ»ç–—å¯¹è¯æ•°æ®**: 4000æ¡é«˜è´¨é‡ä¸­æ–‡åŒ»ç–—å’¨è¯¢å¯¹è¯
- **è¯ç‰©çŸ¥è¯†å¢å¼º**: æ•´åˆå¸¸è§è¯ç‰©çš„ç”¨æ³•ã€å‰¯ä½œç”¨ã€ç¦å¿Œç—‡
- **æ•°æ®ç±»å‹**: 
  - ç—‡çŠ¶å’¨è¯¢
  - æ£€æŸ¥ç»“æœè§£è¯»
  - ç”¨è¯æŒ‡å¯¼
  - å¥åº·å»ºè®®
  - æƒ…ç»ªæ”¯æŒ

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹æ¶æ„
- **åŸºç¡€æ¨¡å‹**: Qwen3-VL-30B (30Bå‚æ•°)
- **å¾®è°ƒæ–¹æ³•**: LoRA (Low-Rank Adaptation)
- **LoRA ç§©**: 128
- **é€‚é…å™¨å¤§å°**: ~200-300 MB

### æ”¯æŒçš„å¹³å°
- âœ… **Apple Silicon** (M1/M2/M3) - MLX ä¼˜åŒ–
- âœ… **NVIDIA GPU** - CUDA æ”¯æŒ
- âœ… **CPU** - é€šç”¨æ”¯æŒ

### æ¨ç†æ€§èƒ½
- **Apple M2 Max**: ~20-30 tokens/s
- **NVIDIA RTX 4090**: ~40-60 tokens/s
- **CPU (16æ ¸)**: ~2-5 tokens/s

## âš ï¸ ä½¿ç”¨é™åˆ¶

### é€‚ç”¨åœºæ™¯
- âœ… ä¸€èˆ¬å¥åº·å’¨è¯¢
- âœ… æ£€æŸ¥ç»“æœåˆæ­¥è§£è¯»
- âœ… ç”¨è¯å¸¸è¯†ç§‘æ™®
- âœ… å¥åº·ç”Ÿæ´»å»ºè®®

### ä¸é€‚ç”¨åœºæ™¯
- âŒ ç´§æ€¥åŒ»ç–—æƒ…å†µï¼ˆè¯·ç«‹å³å°±åŒ»ï¼‰
- âŒ æœ€ç»ˆè¯Šæ–­ï¼ˆéœ€è¦ä¸“ä¸šåŒ»ç”Ÿï¼‰
- âŒ å¤„æ–¹å¼€å…·ï¼ˆéœ€è¦åŒ»ç”Ÿå¤„æ–¹ï¼‰
- âŒ æ‰‹æœ¯å»ºè®®ï¼ˆéœ€è¦ä¸“ç§‘åŒ»ç”Ÿï¼‰

### âš ï¸ å…è´£å£°æ˜

**æœ¬æ¨¡å‹ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€‚**

- æ¨¡å‹å¯èƒ½äº§ç”Ÿä¸å‡†ç¡®çš„ä¿¡æ¯
- ä¸åº”ä½œä¸ºåŒ»ç–—å†³ç­–çš„å”¯ä¸€ä¾æ®
- é‡åˆ°å¥åº·é—®é¢˜è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
- ç´§æ€¥æƒ…å†µè¯·ç«‹å³å°±åŒ»æˆ–æ‹¨æ‰“æ€¥æ•‘ç”µè¯

## ğŸ“„ è®¸å¯è¯

æœ¬æ¨¡å‹åŸºäº **Apache 2.0** è®¸å¯è¯å¼€æºã€‚

ä½¿ç”¨æœ¬æ¨¡å‹å³è¡¨ç¤ºä½ åŒæ„ï¼š
- éµå®ˆ Apache 2.0 è®¸å¯è¯æ¡æ¬¾
- ç†è§£æ¨¡å‹çš„é™åˆ¶å’Œå…è´£å£°æ˜
- è´Ÿè´£ä»»åœ°ä½¿ç”¨æ¨¡å‹

## ğŸ™ è‡´è°¢

- **åŸºç¡€æ¨¡å‹**: Qwen å›¢é˜Ÿçš„ Qwen3-VL-30B
- **æ¡†æ¶**: MLX å›¢é˜Ÿçš„ Apple Silicon ä¼˜åŒ–
- **è®­ç»ƒæ•°æ®**: æ•´åˆè‡ªå…¬å¼€åŒ»ç–—å’¨è¯¢æ•°æ®é›†

## ğŸ“ è”ç³»æ–¹å¼

- **GitHub**: [ä½ çš„GitHub]
- **Hugging Face**: [ä½ çš„ä¸»é¡µ]
- **é‚®ç®±**: [ä½ çš„é‚®ç®±]

## ğŸ”— ç›¸å…³é“¾æ¥

- [V3è®­ç»ƒä½¿ç”¨æŒ‡å—](./V3è®­ç»ƒä½¿ç”¨æŒ‡å—.md)
- [è®­ç»ƒä»£ç ä»“åº“](https://github.com/ä½ çš„ç”¨æˆ·å/ä½ çš„ä»“åº“)
- [Qwen å®˜æ–¹æ–‡æ¡£](https://github.com/QwenLM/Qwen)
- [MLX æ–‡æ¡£](https://ml-explore.github.io/mlx/)

---

**å¼€å§‹ä½¿ç”¨å§ï¼** ğŸš€

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨ Discussions ä¸­äº¤æµã€‚

*æœ€åæ›´æ–°: {datetime.now().strftime("%Y-%m-%d")}*
"""
        
        readme_path = upload_dir / "README.md"
        readme_path.write_text(readme_content, encoding='utf-8')
        print("  âœ… README.md å·²ç”Ÿæˆ")
    
    def upload_model(self, repo_id, upload_dir):
        """ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face"""
        print(f"\nâ¬†ï¸  ä¸Šä¼ æ¨¡å‹åˆ° {repo_id}...")
        
        try:
            url = upload_folder(
                folder_path=str(upload_dir),
                repo_id=repo_id,
                repo_type="model",
                commit_message="Upload Qwen3-VL-30B Medical V3 Precision model"
            )
            
            print(f"âœ… ä¸Šä¼ æˆåŠŸï¼")
            print(f"ğŸ”— æ¨¡å‹é“¾æ¥: https://huggingface.co/{repo_id}")
            return True
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
            return False
    
    def cleanup(self, upload_dir):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        import shutil
        if upload_dir.exists():
            shutil.rmtree(upload_dir)
            print("âœ… æ¸…ç†å®Œæˆ")
    
    def run(self):
        """è¿è¡Œå®Œæ•´çš„ä¸Šä¼ æµç¨‹"""
        print("=" * 60)
        print("ğŸš€ Hugging Face æ¨¡å‹ä¸Šä¼ å·¥å…·")
        print("=" * 60)
        
        # 1. æ£€æŸ¥æ–‡ä»¶
        if not self.check_files():
            print("\nâŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶ï¼Œä¸Šä¼ ä¸­æ­¢")
            return False
        
        # 2. ç™»å½•
        if not self.login_hf():
            return False
        
        # 3. è·å–ä»“åº“åç§°
        print("\nğŸ“ è®¾ç½®ä»“åº“ä¿¡æ¯")
        default_name = "Qwen3-VL-30B-Medical-V3-Precision"
        repo_name = input(f"ä»“åº“åç§° (é»˜è®¤: {default_name}): ").strip()
        if not repo_name:
            repo_name = default_name
        
        # 4. è¯¢é—®æ˜¯å¦ç§æœ‰
        private_input = input("è®¾ä¸ºç§æœ‰ä»“åº“? (y/N): ").strip().lower()
        private = private_input == 'y'
        
        # 5. åˆ›å»ºä»“åº“
        repo_id = self.create_repository(repo_name, private)
        if not repo_id:
            return False
        
        # 6. å‡†å¤‡ä¸Šä¼ ç›®å½•
        upload_dir = self.prepare_upload_dir()
        
        # 7. ç¡®è®¤ä¸Šä¼ 
        print(f"\nğŸ“‹ å‡†å¤‡ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶åˆ° {repo_id}:")
        for file in upload_dir.iterdir():
            if file.is_file():
                size = file.stat().st_size / (1024 * 1024)
                print(f"  - {file.name} ({size:.1f} MB)")
        
        confirm = input("\nç¡®è®¤ä¸Šä¼ ? (Y/n): ").strip().lower()
        if confirm == 'n':
            print("âŒ ä¸Šä¼ å·²å–æ¶ˆ")
            self.cleanup(upload_dir)
            return False
        
        # 8. ä¸Šä¼ 
        success = self.upload_model(repo_id, upload_dir)
        
        # 9. æ¸…ç†
        self.cleanup(upload_dir)
        
        if success:
            print("\n" + "=" * 60)
            print("âœ… ä¸Šä¼ å®Œæˆï¼")
            print("=" * 60)
            print(f"\nğŸ”— ä½ çš„æ¨¡å‹: https://huggingface.co/{repo_id}")
            print("\nğŸ“ ä¸‹ä¸€æ­¥:")
            print("1. è®¿é—®æ¨¡å‹é¡µé¢ï¼ŒæŸ¥çœ‹å’Œç¼–è¾‘ä¿¡æ¯")
            print("2. æµ‹è¯•æ¨¡å‹èƒ½å¦æ­£å¸¸ä¸‹è½½å’Œä½¿ç”¨")
            print("3. åˆ†äº«ä½ çš„æ¨¡å‹é“¾æ¥")
            print("\nğŸ’¡ ä½¿ç”¨ä½ çš„æ¨¡å‹:")
            print(f"mlx_lm.generate --model Qwen/Qwen2-VL-30B \\")
            print(f"  --adapter-path {repo_id} \\")
            print(f'  --prompt "ä½ çš„é—®é¢˜"')
        
        return success


def main():
    """ä¸»å‡½æ•°"""
    uploader = ModelUploader()
    success = uploader.run()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()

