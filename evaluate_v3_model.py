#!/usr/bin/env python3
"""
V3æ¨¡å‹è¯„ä¼°è„šæœ¬
æµ‹è¯•V3æ¨¡å‹çš„ç²¾å‡†åº¦å’Œäººæƒ…å‘³è¡¨ç°
"""
import sys
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

console = Console()

# MLXå¯¼å…¥
try:
    from mlx_lm import load, generate
    MLX_AVAILABLE = True
except ImportError:
    MLX_AVAILABLE = False
    console.print("[red]âŒ MLXæœªå®‰è£…[/red]")
    sys.exit(1)


# æµ‹è¯•ç”¨ä¾‹
TEST_CASES = [
    {
        "name": "è¡€å‹å’¨è¯¢ï¼ˆéœ€è¦ç²¾å‡†æ•°å€¼ï¼‰",
        "prompt": "æˆ‘çš„è¡€å‹æ˜¯145/95 mmHgï¼Œè¿™ä¸ªæ•°å€¼æ­£å¸¸å—ï¼Ÿéœ€è¦åƒè¯å—ï¼Ÿ",
        "expected": "ç²¾å‡†æ•°å€¼èŒƒå›´ã€å…·ä½“å»ºè®®ã€ä¿æŒæ¸©æš–"
    },
    {
        "name": "è¡€ç³–æ£€æŸ¥ï¼ˆéœ€è¦è¯¦ç»†åˆ†æï¼‰",
        "prompt": "ç©ºè…¹è¡€ç³–7.2 mmol/Lï¼Œé¤å2å°æ—¶11.5 mmol/Lï¼Œè¿™æ˜¯ç³–å°¿ç—…å—ï¼Ÿ",
        "expected": "å‡†ç¡®è¯Šæ–­æ ‡å‡†ã€æ•°å€¼åˆ†æã€å…·ä½“æ²»ç–—å»ºè®®"
    },
    {
        "name": "è¯ç‰©å’¨è¯¢ï¼ˆéœ€è¦å…·ä½“æ–¹æ¡ˆï¼‰",
        "prompt": "æˆ‘æœ‰é«˜è¡€å‹ï¼ŒåŒ»ç”Ÿå¼€äº†é™å‹è¯ï¼Œä»€ä¹ˆæ—¶å€™åƒæ•ˆæœæœ€å¥½ï¼Ÿ",
        "expected": "å…·ä½“æ—¶é—´å»ºè®®ã€ç”¨è¯æ³¨æ„äº‹é¡¹ã€ä¿æŒå…³æ€€"
    },
    {
        "name": "ç—‡çŠ¶åˆ†æï¼ˆéœ€è¦ç»¼åˆåˆ¤æ–­ï¼‰",
        "prompt": "æœ€è¿‘å¤´æ™•ã€ä¹åŠ›ã€é£Ÿæ¬²ä¸æŒ¯ï¼Œå¯èƒ½æ˜¯ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
        "expected": "å¯èƒ½è¯Šæ–­ã€å»ºè®®æ£€æŸ¥é¡¹ç›®ã€æ¸©æš–å®‰æ…°"
    },
    {
        "name": "æƒ…ç»ªæ”¯æŒï¼ˆéœ€è¦äººæƒ…å‘³ï¼‰",
        "prompt": "ç¡®è¯Šç³–å°¿ç—…åæˆ‘å¾ˆç„¦è™‘ï¼Œæ‹…å¿ƒä»¥åçš„ç”Ÿæ´»...",
        "expected": "åŒç†å¿ƒã€æƒ…ç»ªæ”¯æŒã€å®é™…å»ºè®®"
    }
]


def load_v3_model():
    """åŠ è½½V3æ¨¡å‹"""
    # å°è¯•åŠ è½½èåˆç‰ˆ
    fused_path = "/Users/plutoguo/.lmstudio/models/local/Qwen3-VL-30B-Medical-V3-Precision"
    adapter_path = "adapters_v3_precision"
    base_model_path = "/Users/plutoguo/.lmstudio/models/local/Qwen3-VL-30B-Medical-V2-Fused"
    
    console.print("[cyan]ğŸ”§ åŠ è½½V3æ¨¡å‹...[/cyan]")
    
    # å…ˆå°è¯•èåˆç‰ˆ
    if Path(fused_path).exists():
        console.print(f"[green]âœ… ä½¿ç”¨èåˆç‰ˆ: {fused_path}[/green]")
        try:
            model, tokenizer = load(fused_path)
            return model, tokenizer, "èåˆç‰ˆ"
        except Exception as e:
            console.print(f"[yellow]âš ï¸  èåˆç‰ˆåŠ è½½å¤±è´¥: {e}[/yellow]")
    
    # å°è¯•adapterç‰ˆ
    if Path(adapter_path).exists() and Path(base_model_path).exists():
        console.print(f"[green]âœ… ä½¿ç”¨Adapterç‰ˆ[/green]")
        try:
            model, tokenizer = load(base_model_path, adapter_path=adapter_path)
            return model, tokenizer, "Adapterç‰ˆ"
        except Exception as e:
            console.print(f"[yellow]âš ï¸  Adapterç‰ˆåŠ è½½å¤±è´¥: {e}[/yellow]")
    
    console.print("[red]âŒ æ— æ³•åŠ è½½V3æ¨¡å‹[/red]")
    return None, None, None


def evaluate_response(prompt: str, response: str) -> dict:
    """è¯„ä¼°å›å¤è´¨é‡"""
    scores = {
        "medical_terms": 0,
        "numerical_precision": 0,
        "specificity": 0,
        "empathy": 0,
        "warmth": 0
    }
    
    # åŒ»å­¦æœ¯è¯­
    medical_terms = [
        "é«˜è¡€å‹", "ç³–å°¿ç—…", "è¡€å‹", "è¡€ç³–", "è¯Šæ–­", "æ²»ç–—",
        "è¯ç‰©", "æ£€æŸ¥", "æŒ‡æ ‡", "æ•°å€¼", "èŒƒå›´", "æ­£å¸¸å€¼"
    ]
    scores["medical_terms"] = sum(1 for term in medical_terms if term in response)
    
    # æ•°å€¼ç²¾åº¦
    import re
    numbers = re.findall(r'\d+\.?\d*', response)
    units = ["mmHg", "mmol/L", "mg/dL", "U/L", "g/L"]
    has_units = any(unit in response for unit in units)
    scores["numerical_precision"] = len(numbers) + (2 if has_units else 0)
    
    # å…·ä½“æ€§
    specific_words = ["å…·ä½“", "å»ºè®®", "æ–¹æ¡ˆ", "æ­¥éª¤", "é¦–å…ˆ", "å…¶æ¬¡", "ç„¶å"]
    scores["specificity"] = sum(1 for word in specific_words if word in response)
    
    # äººæƒ…å‘³
    empathy_words = ["ç†è§£", "æ‹…å¿ƒ", "ç„¦è™‘", "å…³å¿ƒ", "æ”¯æŒ"]
    scores["empathy"] = sum(1 for word in empathy_words if word in response)
    
    warmth_words = ["æ‚¨", "è¯·", "å¸Œæœ›", "ç¥", "é™ªä¼´"]
    scores["warmth"] = sum(1 for word in warmth_words if word in response)
    
    return scores


def run_evaluation():
    """è¿è¡Œè¯„ä¼°"""
    console.print(Panel.fit(
        "[bold cyan]ğŸ§ª V3æ¨¡å‹è¯„ä¼°å·¥å…·[/bold cyan]\n"
        "æµ‹è¯•ç²¾å‡†åº¦å’Œäººæƒ…å‘³è¡¨ç°",
        border_style="cyan"
    ))
    console.print()
    
    # åŠ è½½æ¨¡å‹
    model, tokenizer, version = load_v3_model()
    if model is None:
        console.print("[red]âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¯„ä¼°[/red]")
        return
    
    console.print(f"[green]âœ… æ¨¡å‹å·²åŠ è½½ ({version})[/green]")
    console.print()
    
    # è¿è¡Œæµ‹è¯•
    results = []
    
    for i, test_case in enumerate(TEST_CASES, 1):
        console.print(f"[cyan]{'='*60}[/cyan]")
        console.print(f"[bold]æµ‹è¯• {i}/{len(TEST_CASES)}: {test_case['name']}[/bold]")
        console.print(f"[yellow]é—®é¢˜:[/yellow] {test_case['prompt']}")
        console.print()
        
        # ç”Ÿæˆå›å¤
        try:
            response = generate(
                model,
                tokenizer,
                prompt=test_case['prompt'],
                max_tokens=400,
                verbose=False
            )
            
            console.print(f"[green]å›å¤:[/green]")
            console.print(response)
            console.print()
            
            # è¯„ä¼°
            scores = evaluate_response(test_case['prompt'], response)
            console.print(f"[blue]è¯„åˆ†:[/blue]")
            console.print(f"  - åŒ»å­¦æœ¯è¯­: {scores['medical_terms']}")
            console.print(f"  - æ•°å€¼ç²¾åº¦: {scores['numerical_precision']}")
            console.print(f"  - å…·ä½“æ€§: {scores['specificity']}")
            console.print(f"  - åŒç†å¿ƒ: {scores['empathy']}")
            console.print(f"  - æ¸©æš–åº¦: {scores['warmth']}")
            
            results.append({
                "name": test_case['name'],
                "prompt": test_case['prompt'],
                "response": response,
                "scores": scores
            })
            
        except Exception as e:
            console.print(f"[red]âŒ ç”Ÿæˆå¤±è´¥: {e}[/red]")
        
        console.print()
    
    # ç”Ÿæˆæ€»ç»“
    console.print("[cyan]" + "="*60 + "[/cyan]")
    console.print("[bold green]ğŸ“Š è¯„ä¼°æ€»ç»“[/bold green]")
    console.print()
    
    if results:
        # åˆ›å»ºè¡¨æ ¼
        table = Table(title="V3æ¨¡å‹è¯„ä¼°ç»“æœ")
        table.add_column("æµ‹è¯•ç”¨ä¾‹", style="cyan")
        table.add_column("åŒ»å­¦æœ¯è¯­", justify="center")
        table.add_column("æ•°å€¼ç²¾åº¦", justify="center")
        table.add_column("å…·ä½“æ€§", justify="center")
        table.add_column("åŒç†å¿ƒ", justify="center")
        table.add_column("æ¸©æš–åº¦", justify="center")
        
        avg_scores = {
            "medical_terms": 0,
            "numerical_precision": 0,
            "specificity": 0,
            "empathy": 0,
            "warmth": 0
        }
        
        for result in results:
            scores = result['scores']
            table.add_row(
                result['name'],
                str(scores['medical_terms']),
                str(scores['numerical_precision']),
                str(scores['specificity']),
                str(scores['empathy']),
                str(scores['warmth'])
            )
            
            for key in avg_scores:
                avg_scores[key] += scores[key]
        
        # è®¡ç®—å¹³å‡å€¼
        n = len(results)
        for key in avg_scores:
            avg_scores[key] /= n
        
        table.add_row(
            "[bold]å¹³å‡åˆ†[/bold]",
            f"[bold]{avg_scores['medical_terms']:.1f}[/bold]",
            f"[bold]{avg_scores['numerical_precision']:.1f}[/bold]",
            f"[bold]{avg_scores['specificity']:.1f}[/bold]",
            f"[bold]{avg_scores['empathy']:.1f}[/bold]",
            f"[bold]{avg_scores['warmth']:.1f}[/bold]"
        )
        
        console.print(table)
        console.print()
        
        # ç»¼åˆè¯„ä»·
        precision_score = (
            avg_scores['medical_terms'] + 
            avg_scores['numerical_precision'] + 
            avg_scores['specificity']
        ) / 3
        
        empathy_score = (
            avg_scores['empathy'] + 
            avg_scores['warmth']
        ) / 2
        
        console.print(f"[bold cyan]ç»¼åˆè¯„ä»·:[/bold cyan]")
        console.print(f"  ç²¾å‡†åº¦å¾—åˆ†: [green]{precision_score:.2f}[/green]")
        console.print(f"  äººæƒ…å‘³å¾—åˆ†: [green]{empathy_score:.2f}[/green]")
        console.print(f"  ç»¼åˆå¾—åˆ†: [bold green]{(precision_score + empathy_score) / 2:.2f}[/bold green]")


def main():
    """ä¸»å‡½æ•°"""
    run_evaluation()


if __name__ == "__main__":
    main()



