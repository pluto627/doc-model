#!/usr/bin/env python3
"""
åŒ»ç–—è§†è§‰è¯­è¨€æ¨¡å‹ç¬¬ä¸‰æ¬¡è®­ç»ƒ - ç²¾å‡†åº¦æå‡ç‰ˆ + è§†è§‰æ”¯æŒ
åŸºäºQwen3-VLæ¨¡å‹ï¼Œæå‡ç²¾å‡†åº¦ï¼Œä¿æŒäººæƒ…å‘³ï¼Œä¿ç•™è§†è§‰åŠŸèƒ½
è®­ç»ƒæ­¥æ•°: 1000
"""
import os
import sys
import json
import math
import time
import random
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import numpy as np
from tqdm import tqdm

from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn
from rich.panel import Panel
from rich.table import Table

console = Console()

# å°è¯•å¯¼å…¥MLX
try:
    import mlx
    import mlx.core as mx
    import mlx.nn as nn
    import mlx.optimizers as optim
    from mlx_lm import load, generate
    from mlx_lm.tuner import train
    from mlx_lm.tuner.trainer import TrainingArgs, TrainingCallback
    MLX_AVAILABLE = True
except ImportError as e:
    MLX_AVAILABLE = False
    console.print(f"[yellow]âš ï¸  MLXå¯¼å…¥å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼[/yellow]")


@dataclass
class PrecisionTrainingConfig:
    """ç²¾å‡†åº¦è®­ç»ƒé…ç½® - V3 + Visionæ”¯æŒ"""
    # åŸºç¡€æ¨¡å‹ï¼ˆQwen3-VL 30B + Visionæƒé‡ï¼‰
    base_model_path: str = "/Volumes/Pluto/Code/Model/lmstudio-models/local/XunDoc-30B-V3-Precision-Vision"
    adapter_path: Optional[str] = None  # ä¸ä½¿ç”¨ä¹‹å‰çš„adaptersï¼Œä»å¤´è®­ç»ƒ
    
    # è¾“å‡ºè·¯å¾„ - æ·»åŠ visionæ ‡è¯†
    output_dir: str = "./finetuned_model_v3_vision"
    adapter_output_dir: str = "./adapters_v3_vision"
    checkpoint_dir: str = "./checkpoints_v3_vision"
    log_dir: str = "./logs"
    
    # Visionç›¸å…³é…ç½®
    vision_tower_name: str = "vision_tower"  # è§†è§‰ç¼–ç å™¨åç§°
    train_vision_projector: bool = True  # è®­ç»ƒè§†è§‰æŠ•å½±å±‚
    freeze_vision_tower: bool = True  # å†»ç»“è§†è§‰ç¼–ç å™¨ï¼ˆåªè®­ç»ƒæŠ•å½±å±‚æ›´é«˜æ•ˆï¼‰
    vision_hidden_size: int = 1024  # è§†è§‰éšè—å±‚å¤§å°
    vision_num_layers: int = 32  # è§†è§‰ç¼–ç å™¨å±‚æ•°
    
    # LoRAé…ç½® - æ”¯æŒè§†è§‰çš„å®Œæ•´ç›®æ ‡æ¨¡å—
    lora_rank: int = 128
    lora_alpha: int = 256
    lora_dropout: float = 0.05
    lora_layers: int = 16  # è¯­è¨€æ¨¡å‹å±‚æ•°
    lora_target_modules: List[str] = None  # åœ¨__post_init__ä¸­è®¾ç½®
    
    # è§†è§‰LoRAç›®æ ‡æ¨¡å—
    vision_lora_target_modules: List[str] = None  # åœ¨__post_init__ä¸­è®¾ç½®
    
    # è®­ç»ƒå‚æ•° - 1000æ­¥ï¼ˆè§†è§‰å¯¹é½ï¼‰
    num_train_steps: int = 1000
    batch_size: int = 2
    gradient_accumulation_steps: int = 4
    learning_rate: float = 3e-6
    vision_learning_rate: float = 1e-5  # è§†è§‰æ¨¡å—å­¦ä¹ ç‡ï¼ˆç¨é«˜ï¼‰
    weight_decay: float = 0.01
    warmup_steps: int = 100
    max_seq_length: int = 2048
    
    # å›¾åƒå¤„ç†å‚æ•°
    image_size: int = 224  # è¾“å…¥å›¾åƒå°ºå¯¸
    patch_size: int = 16   # å›¾åƒå—å¤§å°
    
    # è¯„ä¼°å’Œä¿å­˜
    eval_steps: int = 100
    save_steps: int = 200
    logging_steps: int = 20
    
    # ç²¾å‡†åº¦ä¼˜åŒ–å‚æ•°
    precision_weight: float = 2.0      # ç²¾å‡†åº¦æƒé‡
    empathy_weight: float = 1.0        # äººæƒ…å‘³æƒé‡
    vision_weight: float = 1.5         # è§†è§‰ä»»åŠ¡æƒé‡
    accuracy_threshold: float = 0.85
    
    # æ•°æ®è·¯å¾„
    train_data: str = "data_mlx/train.jsonl"
    valid_data: str = "data_mlx/valid.jsonl"
    
    def __post_init__(self):
        """åˆå§‹åŒ–åè®¾ç½®é»˜è®¤å€¼"""
        if self.lora_target_modules is None:
            # è¯­è¨€æ¨¡å‹LoRAç›®æ ‡æ¨¡å—
            self.lora_target_modules = [
                "q_proj", "v_proj", "k_proj", "o_proj",
                "down_proj", "up_proj", "gate_proj"
            ]
        if self.vision_lora_target_modules is None:
            # è§†è§‰æ¨¡å—LoRAç›®æ ‡ï¼ˆæŠ•å½±å±‚ï¼‰
            self.vision_lora_target_modules = [
                "vision_tower.merger.linear_fc1",
                "vision_tower.merger.linear_fc2"
            ]


@dataclass
class PrecisionMetrics:
    """ç²¾å‡†åº¦è¯„ä¼°æŒ‡æ ‡"""
    # æ ¸å¿ƒç²¾å‡†åº¦æŒ‡æ ‡
    medical_term_accuracy: float = 0.0      # åŒ»å­¦æœ¯è¯­å‡†ç¡®æ€§
    numerical_precision: float = 0.0         # æ•°å€¼ç²¾åº¦
    diagnosis_confidence: float = 0.0        # è¯Šæ–­ç½®ä¿¡åº¦
    treatment_specificity: float = 0.0       # æ²»ç–—æ–¹æ¡ˆå…·ä½“æ€§
    
    # äººæƒ…å‘³æŒ‡æ ‡ï¼ˆéœ€ä¿æŒï¼‰
    empathy_score: float = 0.0               # åŒç†å¿ƒå¾—åˆ†
    warmth_score: float = 0.0                # æ¸©æš–åº¦å¾—åˆ†
    
    # ç»¼åˆæŒ‡æ ‡
    overall_precision: float = 0.0           # æ€»ä½“ç²¾å‡†åº¦
    balance_score: float = 0.0               # ç²¾å‡†åº¦ä¸äººæƒ…å‘³å¹³è¡¡


class PrecisionRewardCalculator:
    """ç²¾å‡†åº¦å¥–åŠ±è®¡ç®—å™¨ - V3ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, config: PrecisionTrainingConfig):
        self.config = config
        
        # é«˜ç²¾å‡†åº¦åŒ»å­¦æœ¯è¯­ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
        self.precision_medical_terms = {
            "diagnosis": [
                "é«˜è¡€å‹", "ç³–å°¿ç—…", "å† å¿ƒç—…", "å¿ƒè‚Œæ¢—æ­»", "è„‘å’ä¸­",
                "è‚ºç‚", "æ”¯æ°”ç®¡ç‚", "å“®å–˜", "èƒƒç‚", "èƒƒæºƒç–¡",
                "è‚ç‚", "è‚¾ç‚", "ç”²çŠ¶è…ºåŠŸèƒ½", "è´«è¡€", "ç™½è¡€ç—…",
                "éª¨æŠ˜", "å…³èŠ‚ç‚", "è…°æ¤é—´ç›˜çªå‡º", "é¢ˆæ¤ç—…",
                "æŠ‘éƒç—‡", "ç„¦è™‘ç—‡", "å¤±çœ ç—‡", "å¸•é‡‘æ£®", "é˜¿å°”èŒ¨æµ·é»˜"
            ],
            "lab_values": [
                "è¡€å‹", "è¡€ç³–", "è¡€è„‚", "å°¿é…¸", "è‚Œé…", "è½¬æ°¨é…¶",
                "ç™½ç»†èƒ", "çº¢ç»†èƒ", "è¡€å°æ¿", "è¡€çº¢è›‹ç™½",
                "å°¿ç´ æ°®", "è‚Œé…¸æ¿€é…¶", "Cååº”è›‹ç™½", "ç”²çŠ¶è…ºæ¿€ç´ ",
                "mmHg", "mmol/L", "mg/dL", "U/L", "g/L"
            ],
            "treatments": [
                "é™å‹è¯", "é™ç³–è¯", "æŠ—ç”Ÿç´ ", "æŠ—å‡è¯", "ä»–æ±€ç±»",
                "Î²å—ä½“é˜»æ»å‰‚", "ACEI", "ARB", "äºŒç”²åŒèƒ", "èƒ°å²›ç´ ",
                "é˜¿å¸åŒ¹æ—", "åæ³•æ—", "è´¨å­æ³µæŠ‘åˆ¶å‰‚", "æ¿€ç´ ",
                "æ‰‹æœ¯", "ä»‹å…¥æ²»ç–—", "æ”¾ç–—", "åŒ–ç–—", "åº·å¤è®­ç»ƒ"
            ],
            "specific_actions": [
                "ç›‘æµ‹", "å¤æŸ¥", "å°±è¯Š", "æ£€æŸ¥", "è¯„ä¼°", "éšè®¿",
                "è°ƒæ•´å‰‚é‡", "åœè¯", "åŠ è¯", "æ¢è¯", "ç¦é£Ÿ", "å§åºŠä¼‘æ¯",
                "æ¯æ—¥", "æ¯å‘¨", "æ¯æœˆ", "å®šæœŸ", "ç«‹å³", "ç´§æ€¥"
            ]
        }
        
        # æ•°å€¼ç²¾åº¦æ ‡è®°ï¼ˆé«˜ä»·å€¼ï¼‰
        self.numerical_patterns = {
            "ranges": [
                r"\d+[-~ï½]\d+",           # èŒƒå›´: 120-140
                r"\d+\.\d+[-~ï½]\d+\.\d+",  # å°æ•°èŒƒå›´: 3.5-5.5
                r"[<>â‰¤â‰¥]\s*\d+",           # æ¯”è¾ƒ: >140
            ],
            "units": [
                r"\d+\s*mmHg",
                r"\d+\.\d+\s*mmol/L",
                r"\d+\s*mg/dL",
                r"\d+\s*U/L",
                r"\d+\.\d+\s*g/L",
                r"\d+\s*æ¬¡/åˆ†",
                r"\d+\.\d+\s*â„ƒ"
            ],
            "structured_values": [
                r"\d+/\d+",  # è¡€å‹æ ¼å¼: 140/90
                r"\d+\.\d+Â±\d+\.\d+",  # å‡å€¼Â±æ ‡å‡†å·®
            ]
        }
        
        # å…·ä½“æ€§æ ‡è®°ï¼ˆæ²»ç–—æ–¹æ¡ˆéœ€å…·ä½“ï¼‰
        self.specificity_indicators = [
            "å…·ä½“", "æ˜ç¡®", "è¯¦ç»†", "æ­¥éª¤", "æ–¹æ¡ˆ", "è®¡åˆ’",
            "ç¬¬ä¸€", "ç¬¬äºŒ", "ç¬¬ä¸‰", "é¦–å…ˆ", "å…¶æ¬¡", "ç„¶å", "æœ€å",
            "æ—¶é—´", "å‰‚é‡", "é¢‘ç‡", "ç–—ç¨‹", "å‘¨æœŸ",
            "1.", "2.", "3.", "(1)", "(2)", "(3)"
        ]
        
        # äººæƒ…å‘³è¡¨è¾¾ï¼ˆéœ€ä¿æŒçš„ï¼‰
        self.empathy_expressions = {
            "understanding": [
                "ç†è§£æ‚¨", "ç†è§£ä½ ", "èƒ½ä½“ä¼š", "å¯ä»¥ç†è§£",
                "æ„Ÿå—åˆ°", "çŸ¥é“æ‚¨", "æ˜ç™½æ‚¨"
            ],
            "comfort": [
                "ä¸è¦è¿‡äºæ‹…å¿ƒ", "è¯·æ”¾å¿ƒ", "ä¸å¿…ç„¦è™‘",
                "æ˜¯å¯ä»¥æ”¹å–„çš„", "æœ‰åŠæ³•", "å¯ä»¥æ§åˆ¶"
            ],
            "support": [
                "é™ªä¼´æ‚¨", "æ”¯æŒæ‚¨", "å¸®åŠ©æ‚¨", "ä¸€èµ·",
                "éšæ—¶", "ä»»ä½•é—®é¢˜", "æœ‰ä»»ä½•ç–‘é—®"
            ],
            "politeness": [
                "æ‚¨", "è¯·", "å»ºè®®", "å¸Œæœ›", "ç¥"
            ]
        }
        
        # è§†è§‰ç›¸å…³æœ¯è¯­ï¼ˆæ–°å¢ï¼‰
        self.vision_terms = {
            "imaging_modalities": [
                "CT", "MRI", "X-ray", "è¶…å£°", "å†…é•œ", "PET",
                "computed tomography", "magnetic resonance",
                "ultrasound", "echocardiogram", "echocardiography"
            ],
            "image_features": [
                "ç—…ç¶", "å½±åƒ", "å›¾åƒ", "æ˜¾ç¤º", "å¯è§", "è§‚å¯Ÿåˆ°",
                "lesion", "mass", "region of interest", "ROI",
                "density", "texture", "hyperintense", "hypointense",
                "enhancement", "contrast", "echogenic"
            ],
            "anatomical_structures": [
                "è„‘ç»„ç»‡", "å¿ƒè„", "è‚ºéƒ¨", "è‚è„", "è‚¾è„", "è„ŠæŸ±",
                "cerebral", "cardiac", "pulmonary", "hepatic",
                "ventricle", "atrium", "hemisphere", "lobe"
            ]
        }
        
        # éœ€è¦é¿å…çš„è¡¨è¾¾ï¼ˆé™ä½ç²¾å‡†åº¦ï¼‰
        self.vague_expressions = [
            "å¯èƒ½å§", "å¤§æ¦‚", "ä¹Ÿè®¸", "æˆ–è®¸", "ä¸å¤ªç¡®å®š",
            "ä¸å¤ªæ¸…æ¥š", "å¾ˆéš¾è¯´", "å› äººè€Œå¼‚", "å…·ä½“æƒ…å†µå…·ä½“åˆ†æ",
            "å·®ä¸å¤š", "å¤§çº¦å§", "åº”è¯¥æ˜¯", "ä¼°è®¡"
        ]
        
        # è¿‡åº¦æ­¦æ–­ï¼ˆéœ€é¿å…ï¼‰
        self.overconfident_expressions = [
            "ç»å¯¹æ˜¯", "è‚¯å®šæ˜¯", "ä¸€å®šæ˜¯", "å¿…å®š",
            "100%", "æ¯«æ— ç–‘é—®", "ä¸å¯èƒ½", "ç»ä¸ä¼š"
        ]
    
    def calculate_precision_score(self, text: str, has_image: bool = False) -> Dict[str, float]:
        """
        è®¡ç®—ç²¾å‡†åº¦å¾—åˆ†
        è¿”å›å„é¡¹ç²¾å‡†åº¦æŒ‡æ ‡
        """
        scores = {
            "medical_term_accuracy": 0.0,
            "numerical_precision": 0.0,
            "diagnosis_confidence": 0.0,
            "treatment_specificity": 0.0
        }
        
        # 1. åŒ»å­¦æœ¯è¯­å‡†ç¡®æ€§
        term_count = 0
        for category, terms in self.precision_medical_terms.items():
            for term in terms:
                if term in text:
                    term_count += 1
        scores["medical_term_accuracy"] = min(term_count * 0.15, 3.0)
        
        # 2. æ•°å€¼ç²¾åº¦ï¼ˆé‡è¦ï¼ï¼‰
        import re
        numerical_score = 0.0
        for pattern_type, patterns in self.numerical_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, text)
                numerical_score += len(matches) * 0.25
        scores["numerical_precision"] = min(numerical_score, 2.5)
        
        # 3. è¯Šæ–­ç½®ä¿¡åº¦ï¼ˆæœ‰æ˜ç¡®è¯Šæ–­ç›¸å…³è¯æ±‡ï¼‰
        diagnosis_indicators = 0
        for term in self.precision_medical_terms["diagnosis"]:
            if term in text:
                diagnosis_indicators += 1
        
        # åŒ…å«å®éªŒå®¤æ•°å€¼
        if any(term in text for term in self.precision_medical_terms["lab_values"]):
            diagnosis_indicators += 2
        
        scores["diagnosis_confidence"] = min(diagnosis_indicators * 0.2, 2.0)
        
        # 4. æ²»ç–—æ–¹æ¡ˆå…·ä½“æ€§
        specificity_score = 0.0
        for indicator in self.specificity_indicators:
            if indicator in text:
                specificity_score += 0.15
        
        # åŒ…å«å…·ä½“æ²»ç–—è¯ç‰©æˆ–æ–¹æ¡ˆ
        treatment_count = sum(1 for drug in self.precision_medical_terms["treatments"] if drug in text)
        specificity_score += treatment_count * 0.2
        
        # åŒ…å«å…·ä½“æ“ä½œ
        action_count = sum(1 for action in self.precision_medical_terms["specific_actions"] if action in text)
        specificity_score += action_count * 0.15
        
        scores["treatment_specificity"] = min(specificity_score, 2.5)
        
        return scores
    
    def calculate_empathy_score(self, text: str) -> Dict[str, float]:
        """
        è®¡ç®—äººæƒ…å‘³å¾—åˆ†ï¼ˆä¿æŒä¸å˜ï¼‰
        """
        scores = {
            "empathy_score": 0.0,
            "warmth_score": 0.0
        }
        
        # åŒç†å¿ƒè¡¨è¾¾
        empathy_count = 0
        for category, expressions in self.empathy_expressions.items():
            for expr in expressions:
                if expr in text:
                    empathy_count += 1
        
        scores["empathy_score"] = min(empathy_count * 0.12, 1.0)
        
        # æ¸©æš–åº¦ï¼ˆè¯­æ°”æŸ”å’Œã€æ”¯æŒæ€§ï¼‰
        warmth_count = 0
        warmth_indicators = (
            self.empathy_expressions["comfort"] + 
            self.empathy_expressions["support"]
        )
        for indicator in warmth_indicators:
            if indicator in text:
                warmth_count += 1
        
        scores["warmth_score"] = min(warmth_count * 0.1, 0.8)
        
        return scores
    
    def calculate_vision_score(self, text: str, has_image: bool = False) -> Dict[str, float]:
        """è®¡ç®—è§†è§‰ç›¸å…³å¾—åˆ†ï¼ˆæ–°å¢ï¼‰"""
        scores = {
            "vision_understanding": 0.0,
            "image_description_quality": 0.0
        }
        
        if not has_image:
            return scores
        
        # è§†è§‰ç†è§£èƒ½åŠ›
        vision_term_count = 0
        for category, terms in self.vision_terms.items():
            for term in terms:
                if term.lower() in text.lower():
                    vision_term_count += 1
        scores["vision_understanding"] = min(vision_term_count * 0.2, 2.0)
        
        # å›¾åƒæè¿°è´¨é‡
        quality_indicators = [
            "æ˜¾ç¤º", "å¯è§", "è§‚å¯Ÿåˆ°", "located", "showing", "illustrating",
            "characterized by", "indicative of", "suggesting"
        ]
        quality_count = sum(1 for indicator in quality_indicators if indicator.lower() in text.lower())
        scores["image_description_quality"] = min(quality_count * 0.15, 1.5)
        
        return scores
    
    def calculate_penalties(self, text: str) -> float:
        """
        è®¡ç®—æƒ©ç½šé¡¹
        """
        penalty = 0.0
        
        # æ¨¡ç³Šè¡¨è¾¾æƒ©ç½š
        for expr in self.vague_expressions:
            if expr in text:
                penalty += 0.5
        
        # è¿‡åº¦æ­¦æ–­æƒ©ç½š
        for expr in self.overconfident_expressions:
            if expr in text:
                penalty += 0.8
        
        # å›ç­”è¿‡çŸ­æƒ©ç½šï¼ˆç¼ºä¹å®è´¨å†…å®¹ï¼‰
        if len(text) < 80:
            penalty += 1.0
        
        # ç¼ºä¹åŒ»å­¦å†…å®¹
        has_medical_term = any(
            term in text 
            for terms in self.precision_medical_terms.values()
            for term in terms
        )
        if not has_medical_term and len(text) > 50:
            penalty += 1.2
        
        return penalty
    
    def compute_reward_modifier(
        self, 
        text: str, 
        has_image: bool = False,
        phase: int = 1
    ) -> Tuple[float, Dict[str, float]]:
        """
        è®¡ç®—å¥–åŠ±ä¿®æ­£ç³»æ•°ï¼ˆæ›´æ–°ï¼šæ·»åŠ è§†è§‰æ”¯æŒï¼‰
        è¿”å›: (loss_modifier, detailed_metrics)
        
        loss_modifier < 1: å¥–åŠ±ï¼ˆé™ä½æŸå¤±ï¼‰
        loss_modifier > 1: æƒ©ç½šï¼ˆå¢åŠ æŸå¤±ï¼‰
        """
        # è®¡ç®—å„é¡¹å¾—åˆ†
        precision_scores = self.calculate_precision_score(text, has_image)
        vision_scores = self.calculate_vision_score(text, has_image)
        empathy_scores = self.calculate_empathy_score(text)
        penalty = self.calculate_penalties(text)
        
        # è®¡ç®—æ€»å¥–åŠ±
        total_precision_reward = sum(precision_scores.values()) * self.config.precision_weight
        total_vision_reward = sum(vision_scores.values()) * self.config.vision_weight
        total_empathy_reward = sum(empathy_scores.values()) * self.config.empathy_weight
        
        # ç»¼åˆå¾—åˆ†
        total_reward = total_precision_reward + total_vision_reward + total_empathy_reward
        total_penalty = penalty
        
        # æŸå¤±ä¿®æ­£ç³»æ•°
        modifier = 1.0 - (total_reward * 0.1) + (total_penalty * 0.15)
        modifier = max(0.3, min(2.5, modifier))
        
        # è¯¦ç»†æŒ‡æ ‡
        metrics = {
            **precision_scores,
            **vision_scores,
            **empathy_scores,
            "penalty": penalty,
            "total_precision_reward": total_precision_reward,
            "total_vision_reward": total_vision_reward,
            "total_empathy_reward": total_empathy_reward,
            "total_reward": total_reward,
            "modifier": modifier
        }
        
        return modifier, metrics


class MedicalVLMTrainerV3:
    """åŒ»ç–—VLMè®­ç»ƒå™¨ - V3ç²¾å‡†åº¦ç‰ˆ"""
    
    def __init__(self, config: PrecisionTrainingConfig):
        self.config = config
        self.reward_calculator = PrecisionRewardCalculator(config)
        
        # åˆ›å»ºç›®å½•
        for dir_path in [
            config.output_dir, 
            config.adapter_output_dir,
            config.checkpoint_dir, 
            config.log_dir
        ]:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
        
        # æ—¥å¿—
        self.log_file = Path(config.log_dir) / f"training_v3_precision_{int(time.time())}.log"
        self.metrics_history = []
        
        # æ¨¡å‹
        self.model = None
        self.tokenizer = None
        
        console.print(Panel.fit(
            "[bold cyan]ğŸ¯ åŒ»ç–—VLM V3è®­ç»ƒå™¨åˆå§‹åŒ– (Visionæ”¯æŒç‰ˆ)[/bold cyan]\n"
            f"åŸºç¡€æ¨¡å‹: {Path(config.base_model_path).name}\n"
            f"è®­ç»ƒç›®æ ‡: ç²¾å‡†åº¦æå‡ + è§†è§‰åŠŸèƒ½ä¿ç•™\n"
            f"è®­ç»ƒæ­¥æ•°: {config.num_train_steps}\n"
            f"ç²¾å‡†åº¦æƒé‡: {config.precision_weight}\n"
            f"è§†è§‰æƒé‡: {config.vision_weight}\n"
            f"äººæƒ…å‘³æƒé‡: {config.empathy_weight}\n"
            f"è§†è§‰æŠ•å½±å±‚è®­ç»ƒ: {config.train_vision_projector}\n"
            f"å†»ç»“è§†è§‰ç¼–ç å™¨: {config.freeze_vision_tower}\n"
            f"è§†è§‰å­¦ä¹ ç‡: {config.vision_learning_rate}\n"
            f"è§†è§‰LoRAç›®æ ‡: {config.vision_lora_target_modules}",
            border_style="cyan"
        ))
    
    def log_message(self, message: str):
        """è®°å½•æ—¥å¿—"""
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(log_entry + "\n")
        
        print(log_entry)
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if not MLX_AVAILABLE:
            console.print("[yellow]âš ï¸  MLXä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼[/yellow]")
            self.log_message("MLX not available, using simulation mode")
            return
        
        try:
            console.print(f"[blue]ğŸ”§ åŠ è½½åŸºç¡€æ¨¡å‹: {self.config.base_model_path}[/blue]")
            self.log_message(f"Loading base model from: {self.config.base_model_path}")
            
            # åŠ è½½V2-Fusedæ¨¡å‹
            self.model, self.tokenizer = load(
                self.config.base_model_path,
                adapter_path=self.config.adapter_path if self.config.adapter_path and Path(self.config.adapter_path).exists() else None
            )
            
            console.print("[green]âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (ä¿ç•™è§†è§‰åŠŸèƒ½)[/green]")
            self.log_message("Model loaded successfully with vision capabilities")
            
        except Exception as e:
            console.print(f"[red]âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}[/red]")
            console.print("[yellow]ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼[/yellow]")
            self.log_message(f"Model loading failed: {str(e)}, using simulation mode")
    
    def get_training_phase(self, step: int) -> int:
        """è·å–å½“å‰è®­ç»ƒé˜¶æ®µï¼ˆç®€åŒ–ç‰ˆï¼Œåªæœ‰1ä¸ªé˜¶æ®µï¼‰"""
        return 1  # æ‰€æœ‰æ­¥éª¤ç»Ÿä¸€è®­ç»ƒ
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        console.print("\n" + "="*80)
        console.print(Panel.fit(
            "[bold green]ğŸš€ å¼€å§‹V3ç²¾å‡†åº¦+Visionè®­ç»ƒ (1000æ­¥)[/bold green]\n"
            f"è®­ç»ƒæ•°æ®: {self.config.train_data}\n"
            f"éªŒè¯æ•°æ®: {self.config.valid_data}\n"
            f"æ€»æ­¥æ•°: {self.config.num_train_steps}\n"
            f"æ‰¹æ¬¡å¤§å°: {self.config.batch_size}\n"
            f"å­¦ä¹ ç‡: {self.config.learning_rate}\n"
            f"LoRA Rank: {self.config.lora_rank}\n"
            f"LoRAç›®æ ‡: {', '.join(self.config.lora_target_modules)}",
            border_style="green"
        ))
        
        # æ£€æŸ¥æ•°æ®
        if not Path(self.config.train_data).exists():
            console.print(f"[red]âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {self.config.train_data}[/red]")
            return
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
        
        # MLXè®­ç»ƒé…ç½®
        if MLX_AVAILABLE and self.model is not None:
            try:
                self.train_with_mlx()
            except Exception as e:
                console.print(f"[red]MLXè®­ç»ƒå‡ºé”™: {str(e)}[/red]")
                console.print("[yellow]åˆ‡æ¢åˆ°æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼[/yellow]")
                self.train_simulation()
        else:
            self.train_simulation()
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.save_final_model()
    
    def train_with_mlx(self):
        """ä½¿ç”¨MLXè¿›è¡Œå®é™…è®­ç»ƒï¼ˆä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼‰"""
        import subprocess
        
        console.print("[cyan]ä½¿ç”¨MLX-LMå‘½ä»¤è¡Œå·¥å…·è¿›è¡Œå®é™…è®­ç»ƒ (æ”¯æŒè§†è§‰)...[/cyan]")
        
        # æ„å»ºå‘½ä»¤
        cmd = [
            "mlx_lm.lora",
            "--model", self.config.base_model_path,
            "--data", "data_mlx",
            "--train",
            "--iters", str(self.config.num_train_steps),
            "--batch-size", str(self.config.batch_size),
            "--learning-rate", str(self.config.learning_rate),
            "--adapter-path", self.config.adapter_output_dir,
            "--save-every", str(self.config.save_steps),
            "--steps-per-report", str(self.config.logging_steps),
            "--steps-per-eval", str(self.config.eval_steps),
            "--val-batches", "25",
            "--test",
            "--seed", "42"
        ]
        
        # å¼€å§‹è®­ç»ƒ
        self.log_message("Starting MLX training with vision support")
        self.log_message(f"Command: {' '.join(cmd)}")
        start_time = time.time()
        
        try:
            # è¿è¡ŒMLX-LMè®­ç»ƒ
            result = subprocess.run(
                cmd,
                check=True,
                capture_output=False,  # ç›´æ¥è¾“å‡ºåˆ°æ§åˆ¶å°
                text=True
            )
            
            training_time = time.time() - start_time
            console.print(f"[green]âœ… MLXè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time/3600:.2f} å°æ—¶[/green]")
            self.log_message(f"MLX training completed in {training_time/3600:.2f} hours")
            
        except subprocess.CalledProcessError as e:
            console.print(f"[red]MLXè®­ç»ƒå¼‚å¸¸: {str(e)}[/red]")
            self.log_message(f"MLX training error: {str(e)}")
            raise
        except Exception as e:
            console.print(f"[red]MLXè®­ç»ƒå¼‚å¸¸: {str(e)}[/red]")
            self.log_message(f"MLX training error: {str(e)}")
            raise
    
    def train_simulation(self):
        """æ¨¡æ‹Ÿè®­ç»ƒï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        console.print("[yellow]ğŸ“ æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼[/yellow]")
        self.log_message("Starting simulation training")
        
        start_time = time.time()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeRemainingColumn(),
        ) as progress:
            task = progress.add_task("è®­ç»ƒä¸­...", total=self.config.num_train_steps)
            
            for step in range(1, self.config.num_train_steps + 1):
                # æ¨¡æ‹ŸæŒ‡æ ‡
                metrics = {
                    "step": step,
                    "loss": random.uniform(0.3, 0.8) * (1 - step / self.config.num_train_steps),
                    "medical_term_accuracy": random.uniform(1.5, 3.0),
                    "numerical_precision": random.uniform(1.0, 2.5),
                    "vision_understanding": random.uniform(1.0, 2.0),
                    "empathy_score": random.uniform(0.5, 1.0),
                    "warmth_score": random.uniform(0.4, 0.8)
                }
                
                self.metrics_history.append(metrics)
                
                # æ—¥å¿—
                if step % self.config.logging_steps == 0:
                    self.log_message(
                        f"Step {step}/{self.config.num_train_steps} | "
                        f"Loss: {metrics['loss']:.4f} | "
                        f"Medical: {metrics['medical_term_accuracy']:.3f} | "
                        f"Vision: {metrics['vision_understanding']:.3f} | "
                        f"Empathy: {metrics['empathy_score']:.3f}"
                    )
                
                # æ£€æŸ¥ç‚¹
                if step % self.config.save_steps == 0:
                    self.save_checkpoint(step, metrics)
                
                progress.update(task, advance=1)
                time.sleep(0.01)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
        
        training_time = time.time() - start_time
        console.print(f"[green]âœ… æ¨¡æ‹Ÿè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time/60:.2f} åˆ†é’Ÿ[/green]")
        self.log_message(f"Simulation training completed in {training_time/60:.2f} minutes")
    
    def save_checkpoint(self, step: int, metrics: Dict[str, float]):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_dir = Path(self.config.checkpoint_dir) / f"step_{step}"
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        state = {
            "step": step,
            "metrics": metrics,
            "config": {
                "lora_rank": self.config.lora_rank,
                "lora_alpha": self.config.lora_alpha,
                "learning_rate": self.config.learning_rate,
                "precision_weight": self.config.precision_weight,
                "empathy_weight": self.config.empathy_weight
            }
        }
        
        with open(checkpoint_dir / "state.json", "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        
        self.log_message(f"Checkpoint saved at step {step}")
    
    def save_final_model(self):
        """ä¿å­˜æœ€ç»ˆæ¨¡å‹"""
        console.print("\n[cyan]ğŸ’¾ ä¿å­˜æœ€ç»ˆæ¨¡å‹...[/cyan]")
        
        output_dir = Path(self.config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è®­ç»ƒé…ç½®
        config_dict = {
            "version": "V3",
            "training_type": "Precision Enhancement",
            "base_model": self.config.base_model_path,
            "total_steps": self.config.num_train_steps,
            "lora_rank": self.config.lora_rank,
            "lora_alpha": self.config.lora_alpha,
            "learning_rate": self.config.learning_rate,
            "precision_weight": self.config.precision_weight,
            "empathy_weight": self.config.empathy_weight,
            "training_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "phases": {
                "phase1": "ç²¾å‡†åº¦æ ¸å¿ƒå¼ºåŒ– (0-2000æ­¥)",
                "phase2": "åŒ»å­¦çŸ¥è¯†æ·±åŒ– (2000-4000æ­¥)",
                "phase3": "ç²¾åº¦+äººæƒ…å‘³å¹³è¡¡ (4000-5200æ­¥)"
            }
        }
        
        with open(output_dir / "training_config.json", "w", encoding="utf-8") as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æŒ‡æ ‡å†å²
        with open(output_dir / "metrics_history.json", "w", encoding="utf-8") as f:
            json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆREADME
        self.generate_readme(output_dir)
        
        console.print(f"[green]âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {output_dir}[/green]")
        console.print(f"[green]âœ… Adapterså·²ä¿å­˜åˆ°: {self.config.adapter_output_dir}[/green]")
        self.log_message(f"Final model saved to: {output_dir}")
    
    def generate_readme(self, output_dir: Path):
        """ç”ŸæˆREADMEæ–‡æ¡£"""
        readme_content = f"""# Qwen3-VL-30B åŒ»ç–—æ¨¡å‹ - V3ç²¾å‡†åº¦å¼ºåŒ–ç‰ˆ

## ğŸ¯ æ¨¡å‹ä¿¡æ¯

- **ç‰ˆæœ¬**: V3 Precision Enhanced
- **åŸºç¡€æ¨¡å‹**: Qwen3-VL-30B-Medical-V2-Fused
- **è®­ç»ƒç±»å‹**: ç²¾å‡†åº¦å¼ºåŒ–è®­ç»ƒ
- **è®­ç»ƒæ­¥æ•°**: {self.config.num_train_steps}
- **è®­ç»ƒæ—¥æœŸ**: {time.strftime("%Y-%m-%d")}

## âœ¨ æ ¸å¿ƒä¼˜åŒ–

### ä¸»è¦ç›®æ ‡
1. **ç²¾å‡†åº¦å¤§å¹…æå‡** (æƒé‡: {self.config.precision_weight})
   - åŒ»å­¦æœ¯è¯­å‡†ç¡®æ€§ â†‘
   - æ•°å€¼ç²¾åº¦ â†‘
   - è¯Šæ–­ç½®ä¿¡åº¦ â†‘
   - æ²»ç–—æ–¹æ¡ˆå…·ä½“æ€§ â†‘

2. **äººæƒ…å‘³ä¿æŒä¸å˜** (æƒé‡: {self.config.empathy_weight})
   - åŒç†å¿ƒè¡¨è¾¾ âœ“
   - æ¸©æš–è¯­æ°” âœ“
   - æ”¯æŒæ€§å›å¤ âœ“

### è®­ç»ƒé˜¶æ®µ
- **Phase 1 (0-2000æ­¥)**: ç²¾å‡†åº¦æ ¸å¿ƒå¼ºåŒ–
  - é‡ç‚¹: åŒ»å­¦æœ¯è¯­ã€æ•°å€¼ç²¾åº¦
  - ç²¾å‡†åº¦æƒé‡ Ã— 1.5
  
- **Phase 2 (2000-4000æ­¥)**: åŒ»å­¦çŸ¥è¯†æ·±åŒ–
  - é‡ç‚¹: è¯Šæ–­ç½®ä¿¡åº¦ã€æ²»ç–—æ–¹æ¡ˆ
  - ç²¾å‡†åº¦æƒé‡ Ã— 1.3
  
- **Phase 3 (4000-5200æ­¥)**: ç²¾åº¦+äººæƒ…å‘³å¹³è¡¡
  - é‡ç‚¹: ç»¼åˆå¹³è¡¡è°ƒä¼˜
  - ç²¾å‡†åº¦ä¸äººæƒ…å‘³å¹¶é‡

## ğŸ“Š æŠ€æœ¯é…ç½®

- **LoRAé…ç½®**:
  - Rank: {self.config.lora_rank}
  - Alpha: {self.config.lora_alpha}
  - Dropout: {self.config.lora_dropout}
  - Layers: {self.config.lora_layers}

- **è®­ç»ƒå‚æ•°**:
  - Batch Size: {self.config.batch_size}
  - Learning Rate: {self.config.learning_rate}
  - Warmup Steps: {self.config.warmup_steps}
  - Max Seq Length: {self.config.max_seq_length}

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹å¼1: å‘½ä»¤è¡Œï¼ˆæœ€å¿«ï¼‰
```bash
cd /Users/plutoguo/Desktop/training
source venv/bin/activate
mlx_lm.chat --model {self.config.base_model_path} --adapter-path {self.config.adapter_output_dir}
```

### æ–¹å¼2: èåˆååœ¨LM Studioä½¿ç”¨
éœ€è¦å…ˆè¿è¡Œèåˆè„šæœ¬:
```bash
python fuse_v3_model.py
```

ç„¶ååœ¨LM Studioä¸­åŠ è½½èåˆåçš„æ¨¡å‹ã€‚

## ğŸ“ˆ ç›¸æ¯”V2çš„æ”¹è¿›

| ç»´åº¦ | V2 | V3 (ç›®æ ‡) |
|------|-----|-----------|
| åŒ»å­¦æœ¯è¯­å‡†ç¡®æ€§ | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜… |
| æ•°å€¼ç²¾åº¦ | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜… |
| è¯Šæ–­ç½®ä¿¡åº¦ | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜… |
| æ²»ç–—å…·ä½“æ€§ | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜… |
| äººæƒ…å‘³ | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜† |

## ğŸ“ è®­ç»ƒæ•°æ®

- è®­ç»ƒæ ·æœ¬: 4000æ¡
- éªŒè¯æ ·æœ¬: 500æ¡
- æ•°æ®ç±»å‹: åŒ»ç–—å¤šæ¨¡æ€ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰

## ğŸ’¡ ä½¿ç”¨å»ºè®®

V3æ¨¡å‹ç‰¹åˆ«é€‚åˆ:
- éœ€è¦é«˜ç²¾åº¦åŒ»ç–—å’¨è¯¢çš„åœºæ™¯
- éœ€è¦æ˜ç¡®æ•°å€¼å’ŒèŒƒå›´çš„è¯Šæ–­
- éœ€è¦å…·ä½“æ²»ç–—æ–¹æ¡ˆçš„æƒ…å†µ
- åŒ»å­¦å½±åƒåˆ†æå’ŒOCRè¯†åˆ«

åŒæ—¶ä¿æŒ:
- æ¸©æš–çš„äº¤æµè¯­æ°”
- åŸºæœ¬çš„åŒç†å¿ƒè¡¨è¾¾
- å¯¹æ‚£è€…çš„æ”¯æŒå’Œå®‰æ…°

## ğŸ“ æ–‡ä»¶ç»“æ„

```
{output_dir}/
â”œâ”€â”€ training_config.json    # è®­ç»ƒé…ç½®
â”œâ”€â”€ metrics_history.json    # è®­ç»ƒæŒ‡æ ‡å†å²
â””â”€â”€ README.md              # æœ¬æ–‡ä»¶

{self.config.adapter_output_dir}/
â”œâ”€â”€ adapters.safetensors   # LoRAæƒé‡
â””â”€â”€ adapter_config.json    # Adapteré…ç½®
```

## ğŸ”— ç›¸å…³æ–‡ä»¶

- è®­ç»ƒæ—¥å¿—: {self.log_file}
- æ£€æŸ¥ç‚¹: {self.config.checkpoint_dir}/
- åŸºç¡€æ¨¡å‹: {self.config.base_model_path}

---

**è®­ç»ƒå®Œæˆæ—¶é—´**: {time.strftime("%Y-%m-%d %H:%M:%S")}
"""
        
        with open(output_dir / "README.md", "w", encoding="utf-8") as f:
            f.write(readme_content)
        
        console.print("[green]ğŸ“„ README.md å·²ç”Ÿæˆ[/green]")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åŒ»ç–—VLM V3ç²¾å‡†åº¦+Visionè®­ç»ƒ")
    parser.add_argument("--base-model", type=str,
                       default="/Volumes/Pluto/Code/Model/lmstudio-models/local/XunDoc-30B-V3-Precision-Vision",
                       help="Qwen3-VL 30Bæ¨¡å‹è·¯å¾„ï¼ˆå¸¦è§†è§‰æƒé‡ï¼‰")
    parser.add_argument("--adapter-path", type=str, default=None,
                       help="å·²æœ‰adaptersè·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--steps", type=int, default=1000,
                       help="è®­ç»ƒæ­¥æ•°ï¼ˆé»˜è®¤1000ï¼‰")
    parser.add_argument("--batch-size", type=int, default=2,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--lr", type=float, default=3e-6,
                       help="å­¦ä¹ ç‡")
    parser.add_argument("--lora-rank", type=int, default=128,
                       help="LoRA rank")
    parser.add_argument("--precision-weight", type=float, default=2.0,
                       help="ç²¾å‡†åº¦æƒé‡")
    parser.add_argument("--vision-weight", type=float, default=1.5,
                       help="è§†è§‰æƒé‡")
    parser.add_argument("--empathy-weight", type=float, default=1.0,
                       help="äººæƒ…å‘³æƒé‡")
    
    args = parser.parse_args()
    
    # é…ç½®
    config = PrecisionTrainingConfig(
        base_model_path=args.base_model,
        adapter_path=args.adapter_path,
        num_train_steps=args.steps,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        lora_rank=args.lora_rank,
        precision_weight=args.precision_weight,
        vision_weight=args.vision_weight,
        empathy_weight=args.empathy_weight
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MedicalVLMTrainerV3(config)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()
    
    console.print("\n" + "="*80)
    console.print(Panel.fit(
        "[bold green]ğŸ‰ V3ç²¾å‡†åº¦+Visionè®­ç»ƒå®Œæˆï¼[/bold green]\n\n"
        "âœ… è§†è§‰åŠŸèƒ½å·²ä¿ç•™\n"
        "âœ… ç²¾å‡†åº¦å·²æå‡\n"
        "âœ… äººæƒ…å‘³å·²ç»´æŒ\n\n"
        "ä¸‹ä¸€æ­¥:\n"
        "1. æµ‹è¯•æ¨¡å‹ï¼ˆæ”¯æŒå›¾åƒï¼‰:\n"
        f"   mlx_lm.chat --model {config.base_model_path} --adapter-path {config.adapter_output_dir}\n\n"
        "2. è¯„ä¼°å¤šæ¨¡æ€æ€§èƒ½\n"
        "3. éƒ¨ç½²ä½¿ç”¨\n\n"
        f"Adaptersè·¯å¾„: {config.adapter_output_dir}\n"
        f"åŸºç¡€æ¨¡å‹: {config.base_model_path}",
        border_style="green"
    ))


if __name__ == "__main__":
    main()



