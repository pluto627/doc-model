#!/usr/bin/env python3
"""
åŒ»ç–—å›¾åƒåˆ†æWebåº”ç”¨
æ”¯æŒå›¾åƒå’Œæ–‡æœ¬ä¸Šä¼ ï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œåˆ†æ
"""
import os
import sys
import json
import base64
from pathlib import Path
from datetime import datetime
from typing import Optional

from flask import Flask, render_template, request, jsonify, send_from_directory
from werkzeug.utils import secure_filename
from PIL import Image
import io

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from config import SOURCE_MODEL_PATH

# å°è¯•å¯¼å…¥MLX
try:
    import mlx
    import mlx.core as mx
    from mlx_lm import load, generate
    MLX_AVAILABLE = True
except ImportError:
    MLX_AVAILABLE = False
    print("âš ï¸ MLXä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”")

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MBæœ€å¤§ä¸Šä¼ å¤§å°
app.config['UPLOAD_FOLDER'] = os.path.join(os.path.dirname(__file__), 'uploads')
app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp'}

# åˆ›å»ºä¸Šä¼ ç›®å½•
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# å…¨å±€æ¨¡å‹å˜é‡
model = None
tokenizer = None
model_loaded = False


def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦å…è®¸"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']


def load_model_once():
    """åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰"""
    global model, tokenizer, model_loaded
    
    if model_loaded:
        return model is not None
    
    if not MLX_AVAILABLE:
        print("âš ï¸ MLXä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        model_loaded = True
        return False
    
    try:
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®AIæ¨¡å‹...")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {SOURCE_MODEL_PATH}")
        print(f"â³ è¿™å¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        model, tokenizer = load(SOURCE_MODEL_PATH)
        model_loaded = True
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        print(f"ğŸ’¾ é¢„è®¡å†…å­˜å ç”¨: 15-20GB")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        model_loaded = True
        return False


def generate_response(question: str, image_path: Optional[str] = None) -> str:
    """ç”Ÿæˆå›å¤ - ä½¿ç”¨çœŸå®AIæ¨¡å‹"""
    global model, tokenizer
    
    # ä½¿ç”¨çœŸå®æ¨¡å‹ç”Ÿæˆ
    if model is not None and MLX_AVAILABLE:
        try:
            print(f"ğŸ¤– ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆå›å¤...")
            
            # å‡†å¤‡å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
            images = None
            if image_path:
                try:
                    with Image.open(image_path) as img:
                        images = [img.convert("RGB")]
                except Exception as e:
                    print(f"âš ï¸ å›¾åƒåŠ è½½å¤±è´¥ï¼Œæ”¹ä¸ºçº¯æ–‡æœ¬æ¨¡å¼: {e}")
                    images = None
            
            # æ„å»ºæç¤ºè¯
            if image_path:
                prompt = (
                    "<|im_start|>system\n"
                    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€æœ‰åŒç†å¿ƒçš„åŒ»ç–—å¥åº·åŠ©æ‰‹ã€‚"
                    "ä½ å¯ä»¥è¯»å–å¹¶ç†è§£ç”¨æˆ·ä¸Šä¼ çš„åŒ»ç–—å½±åƒæˆ–æŠ¥å‘Šç…§ç‰‡ï¼Œ"
                    "æå–å…¶ä¸­çš„æ–‡å­—ï¼ˆOCRï¼‰å’Œå…³é”®ä¿¡æ¯ï¼Œå†ç»“åˆç”¨æˆ·é—®é¢˜ç»™å‡ºä¸“ä¸šã€æ¸©æš–çš„å»ºè®®ã€‚"
                    "<|im_end|>\n"
                    "<|im_start|>user\n"
                    "ä»¥ä¸‹æ˜¯æˆ‘ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·å…ˆé˜…è¯»å›¾ç‰‡å†…å®¹ï¼ˆåŒ…å«æ–‡å­—å’Œå½±åƒï¼‰ï¼Œå†å›ç­”æˆ‘çš„é—®é¢˜ï¼š\n"
                    f"é—®é¢˜: {question}"
                    "<|im_end|>\n"
                    "<|im_start|>assistant\n"
                )
            else:
                prompt = (
                    "<|im_start|>system\n"
                    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€æœ‰åŒç†å¿ƒçš„åŒ»ç–—å¥åº·åŠ©æ‰‹ã€‚"
                    "è¯·ç”¨æ¸©æš–ã€ä¸“ä¸šçš„è¯­æ°”å›ç­”ç”¨æˆ·çš„å¥åº·é—®é¢˜ã€‚"
                    "<|im_end|>\n"
                    "<|im_start|>user\n"
                    f"{question}"
                    "<|im_end|>\n"
                    "<|im_start|>assistant\n"
                )
            
            # ç”Ÿæˆå›å¤ - V4.2ä¼˜åŒ–å‚æ•°
            response = generate(
                model,
                tokenizer,
                prompt=prompt,
                images=images,
                max_tokens=512,
                temp=0.7,                    # å¢åŠ å¤šæ ·æ€§
                top_p=0.9,                   # æ ¸é‡‡æ ·
                repetition_penalty=1.1,      # å‡å°‘é‡å¤
                verbose=False
            )
            
            print(f"âœ… AIç”Ÿæˆå®Œæˆ")
            return response.strip()
            
        except Exception as e:
            print(f"âš ï¸ AIç”Ÿæˆå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            print("ğŸ“ å›é€€åˆ°æ¨¡æ‹Ÿå“åº”")
            return generate_simulated_response(question)
    
    # æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”
    print("âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”")
    return generate_simulated_response(question)


def generate_simulated_response(question: str) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”ï¼ˆå½“æ¨¡å‹ä¸å¯ç”¨æ—¶ï¼‰"""
    
    # æ™ºèƒ½å“åº”æ¨¡æ¿
    responses = {
        "è¡€å‹": "æˆ‘ç†è§£æ‚¨å¯¹è¡€å‹çš„æ‹…å¿§ï¼Œè¿™æ˜¯éå¸¸æ­£å¸¸çš„å¥åº·å…³æ³¨ã€‚è¡€å‹çš„æ­£å¸¸èŒƒå›´é€šå¸¸æ˜¯æ”¶ç¼©å‹90-139 mmHgï¼Œèˆ’å¼ å‹60-89 mmHgã€‚å¦‚æœæ‚¨çš„è¡€å‹ç¨å¾®åé«˜ï¼Œå»ºè®®æ‚¨ï¼š\n\n1. å‡å°‘ç›åˆ†æ‘„å…¥\n2. ä¿æŒè§„å¾‹è¿åŠ¨\n3. æ§åˆ¶ä½“é‡\n4. ä¿è¯å……è¶³ç¡çœ \n\nå¦‚æœæŒç»­åé«˜ï¼Œå»ºè®®å’¨è¯¢å¿ƒå†…ç§‘åŒ»ç”Ÿè¿›è¡Œä¸“ä¸šè¯„ä¼°ã€‚è¯·é—®æ‚¨è¿˜æœ‰å…¶ä»–æƒ³äº†è§£çš„å—ï¼Ÿ",
        
        "è¡€ç³–": "æ„Ÿè°¢æ‚¨åˆ†äº«æ£€æµ‹ç»“æœï¼Œæˆ‘æ¥å¸®æ‚¨åˆ†æä¸€ä¸‹ã€‚ç©ºè…¹è¡€ç³–çš„æ­£å¸¸èŒƒå›´ä¸€èˆ¬æ˜¯3.9-6.1 mmol/Lï¼Œé¤å2å°æ—¶è¡€ç³–åº”ä½äº7.8 mmol/Lã€‚\n\nå¦‚æœæ‚¨çš„æ•°å€¼ç•¥é«˜ï¼Œä¸å¿…è¿‡åº¦æ‹…å¿ƒï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ”¹å–„ï¼š\n\n1. æ§åˆ¶ç¢³æ°´åŒ–åˆç‰©æ‘„å…¥\n2. å¢åŠ è¿åŠ¨é‡\n3. ä¿æŒè§„å¾‹ä½œæ¯\n\nå»ºè®®ä¸€å‘¨åå¤æŸ¥ï¼Œå¦‚æœ‰æŒç»­å¼‚å¸¸ï¼Œè¯·å’¨è¯¢å†…åˆ†æ³Œç§‘åŒ»ç”Ÿã€‚",
        
        "xå…‰": "æˆ‘ç†è§£æ‚¨ä¸Šä¼ äº†Xå…‰ç‰‡ï¼Œè®©æˆ‘æ¥å¸®æ‚¨åˆ†æã€‚Xå…‰æ£€æŸ¥æ˜¯å¸¸è§çš„å½±åƒå­¦æ£€æŸ¥æ‰‹æ®µã€‚\n\nè¯·æ³¨æ„ï¼š\n- å›¾åƒè´¨é‡ä¼šå½±å“è¯Šæ–­å‡†ç¡®æ€§\n- éœ€è¦ç»“åˆä¸´åºŠç—‡çŠ¶ç»¼åˆåˆ¤æ–­\n- å»ºè®®ç”±ä¸“ä¸šæ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œè¯¦ç»†è§£è¯»\n\nå¦‚æœæ‚¨æœ‰å…·ä½“çš„ç–‘é—®æˆ–ç—‡çŠ¶ï¼Œè¯·è¯¦ç»†æè¿°ï¼Œè¿™æ ·æˆ‘å¯ä»¥ç»™æ‚¨æ›´æœ‰é’ˆå¯¹æ€§çš„å»ºè®®ã€‚å¿…è¦æ—¶è¯·åŠæ—¶å°±åŒ»ã€‚",
        
        "CT": "æ„Ÿè°¢æ‚¨ä¸Šä¼ CTå½±åƒã€‚CTæ‰«æèƒ½å¤Ÿæä¾›è¯¦ç»†çš„æ–­å±‚å›¾åƒä¿¡æ¯ã€‚\n\nåˆ†æè¦ç‚¹ï¼š\n- CTæŠ¥å‘Šéœ€è¦ä¸“ä¸šåŒ»ç”Ÿç»“åˆä¸´åºŠç»¼åˆåˆ¤æ–­\n- å¦‚å‘ç°å¼‚å¸¸ï¼Œå»ºè®®å’¨è¯¢ç›¸å…³ä¸“ç§‘åŒ»ç”Ÿ\n- å®šæœŸå¤æŸ¥å¾ˆé‡è¦\n\nå¦‚æœæ‚¨å¯¹æŠ¥å‘Šæœ‰ç–‘é—®ï¼Œå»ºè®®æ‚¨ï¼š\n1. æºå¸¦å®Œæ•´æŠ¥å‘Šå°±è¯Š\n2. è¯¦ç»†æè¿°ç—‡çŠ¶\n3. å¬å–ä¸“ç§‘åŒ»ç”Ÿå»ºè®®\n\nè¯·ä¸è¦è¿‡åº¦æ‹…å¿ƒï¼Œå¾ˆå¤šæƒ…å†µä¸‹æ—©å‘ç°æ—©æ²»ç–—æ•ˆæœéƒ½å¾ˆå¥½ã€‚",
        
        "å¿ƒç”µå›¾": "æˆ‘çœ‹åˆ°æ‚¨ä¸Šä¼ äº†å¿ƒç”µå›¾ï¼Œè®©æˆ‘å¸®æ‚¨åšåˆæ­¥åˆ†æã€‚å¿ƒç”µå›¾æ˜¯è¯„ä¼°å¿ƒè„ç”µæ´»åŠ¨çš„é‡è¦æ£€æŸ¥ã€‚\n\næ­£å¸¸å¿ƒç”µå›¾ç‰¹å¾ï¼š\n- å¿ƒç‡ï¼š60-100æ¬¡/åˆ†\n- è§„å¾‹çš„æ³¢å½¢\n- æ­£å¸¸çš„å„æ³¢æ®µé—´æœŸ\n\nå¦‚æœæŠ¥å‘Šæç¤ºå¼‚å¸¸ï¼Œå»ºè®®ï¼š\n1. å’¨è¯¢å¿ƒå†…ç§‘åŒ»ç”Ÿ\n2. ç»“åˆä¸´åºŠç—‡çŠ¶åˆ†æ\n3. å¿…è¦æ—¶åšè¿›ä¸€æ­¥æ£€æŸ¥\n\nå¦‚æœ‰èƒ¸é—·ã€èƒ¸ç—›ç­‰ç—‡çŠ¶ï¼Œè¯·åŠæ—¶å°±åŒ»ã€‚",
        
        "çš®è‚¤": "æˆ‘ç†è§£æ‚¨å¯¹çš®è‚¤é—®é¢˜çš„æ‹…å¿§ã€‚ä»å›¾åƒè§‚å¯Ÿï¼Œå»ºè®®æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n\nåŸºæœ¬æŠ¤ç†ï¼š\n- ä¿æŒæ‚£å¤„æ¸…æ´å¹²ç‡¥\n- é¿å…æŠ“æŒ \n- æ³¨æ„è§‚å¯Ÿå˜åŒ–\n\nå°±åŒ»å»ºè®®ï¼š\n- å¦‚æœ‰æ˜æ˜¾ä¸é€‚ï¼Œå»ºè®®å°±è¯Šçš®è‚¤ç§‘\n- æºå¸¦æ¸…æ™°å›¾ç‰‡ç»™åŒ»ç”Ÿå‚è€ƒ\n- æè¿°ç—‡çŠ¶æŒç»­æ—¶é—´å’Œå˜åŒ–\n\nçš®è‚¤é—®é¢˜ç§ç±»ç¹å¤šï¼Œä¸“ä¸šåŒ»ç”Ÿèƒ½ç»™å‡ºæ›´å‡†ç¡®çš„è¯Šæ–­å’Œæ²»ç–—æ–¹æ¡ˆã€‚",
        
        "default": "æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼Œæˆ‘å¾ˆé«˜å…´èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n\nä½œä¸ºåŒ»ç–—å¥åº·AIåŠ©æ‰‹ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„ä¿¡æ¯ã€‚ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œè¯·æ‚¨è¯¦ç»†æè¿°ï¼š\n\n1. å…·ä½“çš„ç—‡çŠ¶æˆ–é—®é¢˜\n2. æŒç»­æ—¶é—´\n3. ç›¸å…³çš„æ£€æŸ¥ç»“æœ\n4. å½“å‰çš„èº«ä½“çŠ¶å†µ\n\nåŒæ—¶è¯·æ³¨æ„ï¼š\n- AIåˆ†æä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£åŒ»ç”Ÿè¯Šæ–­\n- å¦‚ç—‡çŠ¶ä¸¥é‡ï¼Œè¯·åŠæ—¶å°±åŒ»\n- å®šæœŸä½“æ£€å¾ˆé‡è¦\n\nè¯·é—®æ‚¨æƒ³å’¨è¯¢ä»€ä¹ˆé—®é¢˜ï¼Ÿ"
    }
    
    # æ ¹æ®å…³é”®è¯åŒ¹é…å“åº”
    question_lower = question.lower()
    
    for key, response in responses.items():
        if key in question_lower or key in question:
            return response
    
    return responses["default"]


def process_image(image_path: str) -> dict:
    """å¤„ç†å›¾åƒï¼Œæå–åŸºæœ¬ä¿¡æ¯"""
    try:
        with Image.open(image_path) as img:
            return {
                "width": img.width,
                "height": img.height,
                "format": img.format,
                "mode": img.mode,
                "size_kb": os.path.getsize(image_path) / 1024
            }
    except Exception as e:
        return {"error": str(e)}


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')


@app.route('/api/analyze', methods=['POST'])
def analyze():
    """åˆ†ææ¥å£"""
    try:
        # è·å–æ–‡æœ¬è¾“å…¥
        question = request.form.get('question', '').strip()
        
        if not question:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥é—®é¢˜æˆ–æè¿°'
            }), 400
        
        # å¤„ç†å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
        image_path = None
        image_info = None
        
        if 'image' in request.files:
            file = request.files['image']
            
            if file and file.filename and allowed_file(file.filename):
                # ä¿å­˜æ–‡ä»¶
                filename = secure_filename(file.filename)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"{timestamp}_{filename}"
                image_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                file.save(image_path)
                
                # æå–å›¾åƒä¿¡æ¯
                image_info = process_image(image_path)
                
                print(f"ğŸ“¸ å›¾åƒå·²ä¿å­˜: {image_path}")
        
        # ç”Ÿæˆå›å¤
        print(f"ğŸ’¬ é—®é¢˜: {question[:100]}...")
        response = generate_response(question, image_path)
        print(f"âœ… å›å¤ç”Ÿæˆå®Œæˆ")
        
        return jsonify({
            'success': True,
            'response': response,
            'image_info': image_info,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'
        }), 500


@app.route('/api/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model_loaded,
        'mlx_available': MLX_AVAILABLE,
        'timestamp': datetime.now().isoformat()
    })


@app.route('/uploads/<filename>')
def uploaded_file(filename):
    """è®¿é—®ä¸Šä¼ çš„æ–‡ä»¶"""
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)


if __name__ == '__main__':
    import socket
    
    # è·å–æœ¬æœºIP
    hostname = socket.gethostname()
    local_ip = socket.gethostbyname(hostname)
    
    print("=" * 60)
    print("ğŸ¥ åŒ»ç–—å›¾åƒåˆ†æWebåº”ç”¨")
    print("=" * 60)
    
    # å°è¯•åŠ è½½æ¨¡å‹
    print("\næ­£åœ¨åŠ è½½æ¨¡å‹...")
    load_model_once()
    
    print("\n" + "=" * 60)
    print("ğŸŒ æœåŠ¡å™¨å¯åŠ¨ä¿¡æ¯")
    print("=" * 60)
    print(f"\næœ¬åœ°è®¿é—®: http://localhost:8080")
    print(f"å±€åŸŸç½‘è®¿é—®: http://{local_ip}:8080")
    print("\nåŒä¸€å±€åŸŸç½‘å†…çš„å…¶ä»–è®¾å¤‡å¯ä»¥é€šè¿‡ä¸Šè¿°åœ°å€è®¿é—®")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    print("=" * 60 + "\n")
    
    # å¯åŠ¨æœåŠ¡å™¨ (0.0.0.0 å…è®¸å±€åŸŸç½‘è®¿é—®)
    app.run(host='0.0.0.0', port=8080, debug=False, threaded=True)

